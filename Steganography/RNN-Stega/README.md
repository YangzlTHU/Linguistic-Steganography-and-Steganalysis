# Abstract
Linguistic steganography based on text carrier auto-generation technology is a current topic with great promise and challenges. Limited by the text automatic generation technology or the corresponding text coding methods, the quality of the steganographic text generated by previous methods is inferior, which makes its imperceptibility unsatisfactory. In this paper, we propose a linguistic steganography based on Recurrent Neural Networks (RNN-Stega), which can automatically generate high-quality text covers on the basis of a secret bitstream that needs to be hidden. We trained our model with a large number of artiﬁcially generated samples and obtained a good estimate of the statistical language model. In the text generation process, we propose Fixed-Length Coding (FLC) and Variable-Length-Coding (VLC) to encode words based on their conditional probability distribution. We designed several experiments to test the proposed model from the perspectives of information hiding efﬁciency, information imperceptibility and information hidden capacity. Experimental results show that the proposed model outperforms all the previous related methods and achieves the state of the art performance.
# Method
## RNN language model
<div align=center><img src=https://github.com/YangzlTHU/Linguistic-Steganography-and-Steganalysis/blob/master/Steganography/RNN-Stega/model.png width="1000" height="500"></div>

## Two embedding algorithms

<div align=center><img src=https://github.com/YangzlTHU/Linguistic-Steganography-and-Steganalysis/blob/master/Steganography/RNN-Stega/FLC.png width="400" height="300">
<img src=https://github.com/YangzlTHU/Linguistic-Steganography-and-Steganalysis/blob/master/Steganography/RNN-Stega/VLC.png width="400" height="300">
</div>
 
# Experiments
<div align=center><img src=https://github.com/YangzlTHU/Linguistic-Steganography-and-Steganalysis/blob/master/Steganography/RNN-Stega/table1.png width="600" height="300"></div>
<div align=center><img src=https://github.com/YangzlTHU/Linguistic-Steganography-and-Steganalysis/blob/master/Steganography/RNN-Stega/table4.png width="300" height="300"><img src=https://github.com/YangzlTHU/Linguistic-Steganography-and-Steganalysis/blob/master/Steganography/RNN-Stega/table5.png width="300" height="300"></div>

<div align=center><img src=https://github.com/YangzlTHU/Linguistic-Steganography-and-Steganalysis/blob/master/Steganography/RNN-Stega/ppl&bpw.png width="700" height="300"></div>
<div align=center><img src=https://github.com/YangzlTHU/Linguistic-Steganography-and-Steganalysis/blob/master/Steganography/RNN-Stega/hiddenspace.png width="800" height="500"></div>

# Codes
An implementation via pytorch can be found in [TextSteg](https://github.com/yjs1224/TextSteg)


# For details of the methods and results, please refer to our paper.
```bibtex
@article{yang2018rnn,
  title={RNN-stega: Linguistic steganography based on recurrent neural networks},
  author={Yang, Zhong-Liang and Guo, Xiao-Qing and Chen, Zi-Ming and Huang, Yong-Feng and Zhang, Yu-Jin},
  journal={IEEE Transactions on Information Forensics and Security},
  volume={14},
  number={5},
  pages={1280--1295},
  year={2018},
  publisher={IEEE}
}
```
