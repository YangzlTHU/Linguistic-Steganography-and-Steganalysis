# Linguistic Steganography: From Symbolic Space to Semantic Space

# Abstract
Previous works about linguistic steganography such as synonym substitution and sampling-based methods usually manipulate observed symbols explicitly to conceal secret information, which may give rise to security risks. In this letter, in order to preclude straightforward operation on observed symbols, we explored generation-based linguistic steganography in latent space by means of encoding secret messages in the selection of implicit attributes (semanteme) of natural language. We proposed a novel framework of linguistic semantic steganography based on rejection sampling strategy. Concretely, we utilized controllable text generation model for embedding and semantic classiﬁer for extraction. In experiments, a model based on CTRL and BERT is implemented for further quantitative assessment. Results reveal that our approach is able to achieve satisfactory efﬁciency as well as nearly perfect imperceptibility. 

# Method
- ## Semantic Steganography. 
<div align=center><img src=https://github.com/YangzlTHU/Linguistic-Steganography-and-Steganalysis/blob/master/Steganography/Linguistic-Semantic-Steganography/pics/motivation.png width="400" height="300"> </div>

- ## Model
<div align=center><img src=https://github.com/YangzlTHU/Linguistic-Steganography-and-Steganalysis/blob/master/Steganography/Linguistic-Semantic-Steganography/pics/model.png width="400" height="300"> </div>


This ﬁgure illustrates the basic idea of the framework of linguistic
semantic steganography (left) and that based on rejection sampling strategy
(right). Secret messages are encoded in the selection of semanteme α. In basic
embedding algorithm (left top), stegotext is the direct output of the controllable
text generation model, which may lead to errors in extraction algorithm (left
bottom). To address this gap, we employed rejection sampling strategy (right).
Extraction algorithm acts as a pre-set hypothesis in embedding algorithm to
guarantee absolutely correct extraction at Bob’s end.

# Experiments
<div align=center><img src=https://github.com/YangzlTHU/Linguistic-Steganography-and-Steganalysis/blob/master/Steganography/Linguistic-Semantic-Steganography/pics/space.png width="800" height="250"> </div>

This ﬁgure demonstrates the distribution of stegotext in semantic space under the framework of linguistic semantic steganography when n =2, 4, 8, 16.
Each node represents the semantic feature (pooler output of the ﬁne-tuned BERT-based semantic classiﬁer) of a certain stegotext generated by the proposed method,
which is reduced to a 2-dimensional vector by t-SNE. Semantic space can be divided roughly into n zones to encode log(n)-bit information.

<div align=center><img src=https://github.com/YangzlTHU/Linguistic-Steganography-and-Steganalysis/blob/master/Steganography/Linguistic-Semantic-Steganography/pics/table1.png width="300" height="200">    <img src=https://github.com/YangzlTHU/Linguistic-Steganography-and-Steganalysis/blob/master/Steganography/Linguistic-Semantic-Steganography/pics/table2.png width="300" height="200"> </div>

# Codes
[Linguistic Semantic Steganography](https://github.com/YangzlTHU/Linguistic-Semantic-Steganography)

## For details of the methods and results, please refer to our paper.
```bibtex 
@article{zhang2020linguistic,
  title={Linguistic steganography: From symbolic space to semantic space},
  author={Zhang, Siyu and Yang, Zhongliang and Yang, Jinshuai and Huang, Yongfeng},
  journal={IEEE Signal Processing Letters},
  volume={28},
  pages={11--15},
  year={2020},
  publisher={IEEE}
}
```
